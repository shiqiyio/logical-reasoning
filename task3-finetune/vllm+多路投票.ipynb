{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96d70d7-9d9d-4d1a-9ac4-8e60fe1189de",
   "metadata": {},
   "source": [
    "bash\n",
    "`python -m vllm.entrypoints.openai.api_server --model ./merge  --served-model-name Qwen2-7B-Instruct-lora --max-model-len=4096 --enforce-eager`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27f9ba5-aa4c-493e-b506-91716cf2f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import uuid\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from scipy import sparse\n",
    "#from rank_bm25 import BM25Okapi\n",
    "#import jieba\n",
    "from http import HTTPStatus\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from loguru import logger\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e91f2b6-de52-40b7-ba6c-0b3166710ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(instruction, input):\n",
    "    # 提取选项部分\n",
    "    options = []\n",
    "    for line in input.split('; '):\n",
    "        if line.startswith('A:') or line.startswith('B:') or line.startswith('C:') or line.startswith('D:'):\n",
    "            options.append(line.split(':', 1)[1])\n",
    "\n",
    "    # 构建选项字符串\n",
    "    options_str = '\\n'.join(f\"{'ABCD'[i]}. {o}\" for i, o in enumerate(options))\n",
    "    \n",
    "    # 构建prompt\n",
    "    prompt = f\"\"\"### Context:\n",
    "你是一位逻辑推理专家，擅长解决各种逻辑推理问题。\n",
    "\n",
    "### Observation:\n",
    "以下是一个逻辑推理的题目，形式为单项选择题。所有的问题都基于闭世界假设，即未观测事实都为假。\n",
    "\n",
    "### Skills:\n",
    "你需要运用你的逻辑推理能力，仔细分析并得出正确答案。\n",
    "\n",
    "### Task:\n",
    "请逐步分析问题并得出结论。\n",
    "\n",
    "### Action:\n",
    "根据你的分析，只返回最终的答案。确保回复的格式是 \"A\" \"B\" \"C\" \"D\" 四个选项中的一个。不要提供任何解释或多余信息。如果无法推理出结果或问题模糊不清，请直接返回 \"A\"。\n",
    "\n",
    "### Result:\n",
    "最终答案应该只包括一个字母选项，确保回答简洁明了。\n",
    "\n",
    "### example  \n",
    "提问：有几种不同的方法来计算数字的幂。在这里，你需要根据不同的计算步骤确定相应的结果。选择题 1：若数 2 将自己乘 3 次，而起始乘积因数为 7，那么最终结果是多少？ A: 14; B: 32; C: 56; D: 64  \n",
    "解题思路：题目中提到“数 2 将与自己乘 3 次”，这意味着我们要计算 2^3。同时，题目还提到“起始乘积因数为 7”，这意味着我们需要将计算得到的 2^3 的结果乘以 7。\n",
    "按照这个逻辑，我们先计算 2^3：\n",
    "2^3=2×2×2=8\n",
    "然后，我们将这个结果乘以起始乘积因数 7： \n",
    "8×7=56\n",
    "因此，最终结果是 56。所以正确答案是 C 。\n",
    "\n",
    "### 题目:\n",
    "{instruction}\n",
    "\n",
    "### 问题:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "    \n",
    "def read_and_process_json_file(file_path):\n",
    "    prompts = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for item in data:\n",
    "        instruction = item[\"instruction\"]\n",
    "        input = item[\"input\"]\n",
    "        prompt = get_prompt(instruction, input)\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    return prompts\n",
    "\n",
    "# prompts = read_and_process_json_file(input_file_path) ##list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bed82bb-8f95-4aba-8b7c-ec0717987af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_qwen_api(MODEL_NAME, prompt):\n",
    "    # 这里采用dashscope的api调用模型推理，通过http传输的json封装返回结果\n",
    "    openai_api_key = \"EMPTY\"\n",
    "    openai_api_base = \"http://localhost:8000/v1\"\n",
    "    client = OpenAI(\n",
    "        api_key=openai_api_key,\n",
    "        base_url=openai_api_base,\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "      model=MODEL_NAME,\n",
    "      messages=[\n",
    "                # {'role':'system','content':'你是一个解决推理任务的专家，你需要分析出问题中的每个实体以及响应关系。然后根据问题一步步推理出结果。并且给出正确的结论。'},\n",
    "\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba624db2-505e-41e1-9f5b-bc488e90c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_char(char1, char2, char3,char4,char5):\n",
    "    # 创建一个字典来存储每个字符的出现次数\n",
    "    frequency = {char1: 0, char2: 0, char3: 0,char4: 0,char5: 0}\n",
    "    \n",
    "    # 增加每个字符的出现次数\n",
    "    frequency[char1] += 1\n",
    "    frequency[char2] += 1\n",
    "    frequency[char3] += 1\n",
    "    frequency[char4] += 1\n",
    "    frequency[char5] += 1\n",
    "    \n",
    "    # 找到出现次数最多的字符\n",
    "    most_frequent = max(frequency, key=frequency.get)\n",
    "    \n",
    "    return most_frequent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389e8f50-eff8-447f-903c-d064e7f95979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompts,MODEL_NAME):\n",
    "    answer_list = []\n",
    "\n",
    "    # 送入多线程任务\n",
    "    for prompt in tqdm(prompts, desc=\"Submitting tasks\", total=len(prompts)):\n",
    "        # 统一使用llm 三次调用\n",
    "        # res,res1,res2 = call_qwen_api(MODEL_NAME, prompt),call_qwen_api(MODEL_NAME, prompt),call_qwen_api(MODEL_NAME, prompt)\n",
    "        # # 通过投票函数获取最终结果并返回\n",
    "        # ans = most_frequent_char(res,res1,res2)\n",
    "        res,res1,res2,res3,res4 = call_qwen_api(MODEL_NAME, prompt),call_qwen_api(MODEL_NAME, prompt),call_qwen_api(MODEL_NAME, prompt),call_qwen_api(MODEL_NAME, prompt),call_qwen_api(MODEL_NAME, prompt)\n",
    "        # 通过投票函数获取最终结果并返回\n",
    "        ans = most_frequent_char(res,res1,res2,res3,res4)\n",
    "       \n",
    "        \n",
    "        \n",
    "        answer_list.append(ans)\n",
    "     \n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9aae4fa-42b7-4a3e-b1a1-0190dfa2b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(file_path, data_list):\n",
    "    with open(file_path, 'w') as file:\n",
    "        print(f\"正在写入到{file_path}文件...\")\n",
    "        for item in tqdm(data_list):\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "# 假设这是你的列表\n",
    "\n",
    "\n",
    "# 文件路径\n",
    "# file_path = './answer/answer.txt'\n",
    "\n",
    "# 写入文件\n",
    "# write_list_to_file(file_path, answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43bffba-a990-49a0-ad01-b1ed6f79c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##写入到submit.jsonl中\n",
    "\n",
    "def process_json(json_file_path, answer_list, output_file_path):\n",
    "    # 读取 JSON 文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # 初始化输出数据结构\n",
    "    output_data = []\n",
    "\n",
    "    # 初始化 round_id\n",
    "    round_id = -1\n",
    "    current_instruction = \"\"\n",
    "\n",
    "    # 处理每一项数据\n",
    "    for item in data:\n",
    "        # 如果 instruction 发生变化，增加 round_id\n",
    "        if current_instruction != item['instruction']:\n",
    "            round_id += 1\n",
    "            current_instruction = item['instruction']\n",
    "            current_item = {\n",
    "                'id': f'round1_test_data_{round_id:03d}',\n",
    "                'questions': []\n",
    "            }\n",
    "            output_data.append(current_item)\n",
    "        else:\n",
    "            current_item = output_data[-1]\n",
    "\n",
    "        # 解析 input 字段中的选择题编号\n",
    "        question_number = int(item['input'].split('选择题 ')[1].split(':')[0])\n",
    "\n",
    "        # 获取对应答案\n",
    "        answer = answer_list.pop(0)  # 使用并移除第一个答案\n",
    "\n",
    "        # 添加问题及答案到 questions 列表\n",
    "        current_item['questions'].append({'answer': answer})\n",
    "\n",
    "    # 写入 JSONL 文件\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for item in output_data:\n",
    "            jsonl_file.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    print(\"写入完成！！！\")\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n",
    "    print('执行结束！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3e0981-db6a-4b65-b335-f2f90d039ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_infer(MODEL_NAME,input_file_path,file_path,output_file_path):\n",
    "\n",
    "    prompts = read_and_process_json_file(input_file_path)\n",
    "    print(\"提示词获取成功\")\n",
    "    answer_list = get_answer(prompts,MODEL_NAME)\n",
    "    print(len(answer_list))\n",
    "    # 写入txt文件\n",
    "    write_list_to_file(file_path, answer_list)\n",
    "    process_json(input_file_path, answer_list, output_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "639542c9-a932-4059-90ba-75a2ebf3599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示词获取成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting tasks: 100%|██████████| 1328/1328 [3:15:47<00:00,  8.85s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1328\n",
      "正在写入到./answer/answer.txt文件...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1328/1328 [00:00<00:00, 1769388.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入完成！！！\n",
      "2024-07-29 20:01:15\n",
      "执行结束！\n"
     ]
    }
   ],
   "source": [
    "# MODEL_NAME = '01ai'\n",
    "MODEL_NAME = 'Qwen2-7B-Instruct-lora'\n",
    "input_file_path = './dataset/output_test.json'\n",
    "output_file_path = './answer/vllm_submit.jsonl'\n",
    "file_path = './answer/answer.txt'\n",
    "run_infer(MODEL_NAME,input_file_path,file_path,output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987937ea-b2c7-41c7-a4c6-dad76457e5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logic1",
   "language": "python",
   "name": "logic1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
